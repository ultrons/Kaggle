{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Embedding, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUDA_VISIBLE_DEVICES'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-32e5483e9258>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[1;31m# raise KeyError with the original key value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CUDA_VISIBLE_DEVICES'"
     ]
    }
   ],
   "source": [
    "#print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.6B.100d.txt\n",
      "glove.6B.200d.txt\n",
      "glove.6B.300d.txt\n",
      "glove.6B.50d.txt\n",
      "glove.6B.zip\n",
      "glove.840B.300d.txt\n",
      "glove.840B.300d.zip\n",
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(check_output([\"ls\" , \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/train.csv')\n",
    "test=pd.read_csv('../input/test.csv')\n",
    "\n",
    "#train=train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sentences=train.comment_text.fillna(\"_na_\").values\n",
    "test_sentences=test.comment_text.fillna(\"_na_\").values\n",
    "class_cloumns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y= train[class_cloumns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
       "       '\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"',\n",
       "       \"You, sir, are my hero. Any chance you remember what page that's on?\"], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,   688,\n",
       "           75,     1,   126,   130,   177,    29,   672,  4511, 12052,\n",
       "         1116,    86,   331,    51,  2278, 11448,    50,  6864,    15,\n",
       "           60,  2756,   148,     7,  2937,    34,   117,  1221, 15190,\n",
       "         2825,     4,    45,    59,   244,     1,   365,    31,     1,\n",
       "           38,    27,   143,    73,  3462,    89,  3085,  4583,  2273,\n",
       "          985],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,    52,  2635,    13,   555,  3809,    73,  4556,\n",
       "         2706,    21,    94,    38,   803,  2679,   992,   589,  8377,\n",
       "          182],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,   412,   437,    73,   134,    14,\n",
       "          249,     2,    71,   314,    78,    50,     9,    13,   626,\n",
       "            8,  2284,   492,   502,   102,     4,   611,     2,    35,\n",
       "          325,   126,   363,     3,    29,    38,    27,    52,   208,\n",
       "            2,   434,    57,    36,     1,  2394,    93,     1,   737,\n",
       "          468],\n",
       "       [ 2502,    56,    16,   513,    15,    25,     5,  4236,     3,\n",
       "         1327,     3,  9762,     7,    67,     1,   277,    85,   122,\n",
       "        13503,    37,     9,    51,    19,    42,    10,     1,  1460,\n",
       "          138,  1257,  2153,   426,  1257,   319,     7,    40,    33,\n",
       "            9,   513,    15,    22,    46,    48,   310,   103,   113,\n",
       "           22,     6,    18,    54,  4442,    12,  2394,   275,    15,\n",
       "          277,    25,   105,     2,    33,    11,   206,    45,   267,\n",
       "           35,    69,    41,   542,     2,    16,     5,  5956,    15,\n",
       "           80,    12,   385,    37,     7,   645,    41,    85,    16,\n",
       "            5,  2024,   386,     5,  3057,  3245,    76,    78,   424,\n",
       "           10,     1,   502,   640,  3597,    28,    98,    23,  3542,\n",
       "         4901],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     6,  1677,    19,\n",
       "           29,  3516,    54,  1069,     6,   579,    39,    27,   205,\n",
       "           15]], dtype=int32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic configuration parameters\n",
    "embed_size = 50\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "\n",
    "\n",
    "\n",
    "#Create a Tokenizer class objectand then fit the tokenizer to the training set\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_sentences))\n",
    "tokenized_train = tokenizer.texts_to_sequences(train_sentences)\n",
    "tokenized_test=tokenizer.texts_to_sequences(test_sentences)\n",
    "X_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_file='../input/glove.6B.50d.txt'\n",
    "#embeddings_index = pd.read_table(embedding_file, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embedding_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020940488, 0.64410424)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 50)\n",
      "0.0209405 0.644104 (20000, 50)\n",
      "(159571, 100)\n",
      "[   0    0    0    3    0    0    0    0    0    0  391    0    0 1128    0\n",
      "  798    0    0    0    0    0    0    0    0 1309    0    0    0    0    0\n",
      "    0    0    0  508    0  225    5    0    0  301    0    0   29    0    0\n",
      " 1011    0    0   18   46    1    0    0    0    0    0    0 1310    7    0\n",
      "    0    0    0 1966    0    0    0    0    0    0]\n",
      "[[ -2.46331076e-01   9.85731994e-02  -2.09594828e-01   4.28027846e-01\n",
      "    2.99032550e-01   7.86187026e-01  -5.90618598e-01   1.07381302e+00\n",
      "   -3.73605614e-01   1.07821286e+00   1.75973765e-01   6.29861359e-01\n",
      "   -5.38836693e-01   2.93602594e-01  -3.30034771e-01  -4.77305239e-02\n",
      "   -3.69043331e-02  -6.22412120e-01   7.22511035e-01  -3.60349541e-01\n",
      "    9.32559829e-02  -1.57864883e+00   5.87879482e-01   1.34319584e+00\n",
      "   -3.81112670e-01  -5.83231530e-01  -2.10476059e-01  -5.41824654e-01\n",
      "   -3.13815893e-01  -5.20551072e-01  -7.44250395e-02   2.01783127e-02\n",
      "    1.88962174e-01  -1.07191072e+00  -2.17444704e-03  -7.28827349e-01\n",
      "   -6.88716162e-01  -4.45070404e-01  -8.60529758e-01  -1.54839196e+00\n",
      "   -9.51071234e-01   4.70497508e-01   1.44373227e+00  -9.62543804e-01\n",
      "   -1.16678051e+00  -3.46209065e-01  -6.86330804e-01  -2.90376679e-01\n",
      "   -1.70878873e-01   8.33003854e-02]\n",
      " [  4.18000013e-01   2.49679998e-01  -4.12420005e-01   1.21699996e-01\n",
      "    3.45270008e-01  -4.44569997e-02  -4.96879995e-01  -1.78619996e-01\n",
      "   -6.60229998e-04  -6.56599998e-01   2.78430015e-01  -1.47670001e-01\n",
      "   -5.56770027e-01   1.46579996e-01  -9.50950012e-03   1.16579998e-02\n",
      "    1.02040000e-01  -1.27920002e-01  -8.44299972e-01  -1.21809997e-01\n",
      "   -1.68009996e-02  -3.32789987e-01  -1.55200005e-01  -2.31309995e-01\n",
      "   -1.91809997e-01  -1.88230002e+00  -7.67459989e-01   9.90509987e-02\n",
      "   -4.21249986e-01  -1.95260003e-01   4.00710011e+00  -1.85939997e-01\n",
      "   -5.22870004e-01  -3.16810012e-01   5.92130003e-04   7.44489999e-03\n",
      "    1.77780002e-01  -1.58969998e-01   1.20409997e-02  -5.42230010e-02\n",
      "   -2.98709989e-01  -1.57490000e-01  -3.47579986e-01  -4.56370004e-02\n",
      "   -4.42510009e-01   1.87849998e-01   2.78489990e-03  -1.84110001e-01\n",
      "   -1.15139998e-01  -7.85809994e-01]\n",
      " [  6.80469990e-01  -3.92629988e-02   3.01860005e-01  -1.77919999e-01\n",
      "    4.29619998e-01   3.22460011e-02  -4.13760006e-01   1.32280007e-01\n",
      "   -2.98469990e-01  -8.52530003e-02   1.71179995e-01   2.24189997e-01\n",
      "   -1.00460000e-01  -4.36529994e-01   3.34179997e-01   6.78460002e-01\n",
      "    5.72040007e-02  -3.44480008e-01  -4.27850008e-01  -4.32749987e-01\n",
      "    5.59629977e-01   1.00319996e-01   1.86770007e-01  -2.68539995e-01\n",
      "    3.73339988e-02  -2.09319997e+00   2.21709996e-01  -3.98680001e-01\n",
      "    2.09120005e-01  -5.57250023e-01   3.88260007e+00   4.74660009e-01\n",
      "   -9.56579983e-01  -3.77880007e-01   2.08690003e-01  -3.27520013e-01\n",
      "    1.27509996e-01   8.83589983e-02   1.63509995e-01  -2.16340005e-01\n",
      "   -9.43749994e-02   1.83240008e-02   2.10480005e-01  -3.08800004e-02\n",
      "   -1.97219998e-01   8.22789967e-02  -9.43399966e-02  -7.32970014e-02\n",
      "   -6.46990016e-02  -2.60439992e-01]\n",
      " [  7.08530009e-01   5.70879996e-01  -4.71599996e-01   1.80480003e-01\n",
      "    5.44489980e-01   7.26029992e-01   1.81569993e-01  -5.23930013e-01\n",
      "    1.03809997e-01  -1.75659999e-01   7.88519979e-02  -3.62159997e-01\n",
      "   -1.18290000e-01  -8.33360016e-01   1.19170003e-01  -1.66050002e-01\n",
      "    6.15549982e-02  -1.27189998e-02  -5.66229999e-01   1.36160003e-02\n",
      "    2.28510007e-01  -1.43959999e-01  -6.75489977e-02  -3.81570011e-01\n",
      "   -2.36980006e-01  -1.70369995e+00  -8.66919994e-01  -2.67040014e-01\n",
      "   -2.58899987e-01   1.76699996e-01   3.86759996e+00  -1.61300004e-01\n",
      "   -1.32730007e-01  -6.88809991e-01   1.84440002e-01   5.24639990e-03\n",
      "   -3.38739991e-01  -7.89560005e-02   2.41850004e-01   3.65759999e-01\n",
      "   -3.47270012e-01   2.84830004e-01   7.56929964e-02  -6.21780008e-02\n",
      "   -3.89880002e-01   2.29020000e-01  -2.16169998e-01  -2.25620002e-01\n",
      "   -9.39180031e-02  -8.03749979e-01]\n",
      " [  2.68180013e-01   1.43460006e-01  -2.78770000e-01   1.62569992e-02\n",
      "    1.13839999e-01   6.99230015e-01  -5.13320029e-01  -4.73679990e-01\n",
      "   -3.30749989e-01  -1.38339996e-01   2.70200014e-01   3.09379995e-01\n",
      "   -4.50120002e-01  -4.12699997e-01  -9.93200019e-02   3.80849987e-02\n",
      "    2.97490004e-02   1.00759998e-01  -2.50580013e-01  -5.18180013e-01\n",
      "    3.45580012e-01   4.49220002e-01   4.87910002e-01  -8.08660015e-02\n",
      "   -1.01209998e-01  -1.37769997e+00  -1.08659998e-01  -2.32010007e-01\n",
      "    1.28389997e-02  -4.65079993e-01   3.84629989e+00   3.13620001e-01\n",
      "    1.36429995e-01  -5.22440016e-01   3.30199987e-01   3.37069988e-01\n",
      "   -3.56009990e-01   3.24310005e-01   1.20410003e-01   3.51200014e-01\n",
      "   -6.90430030e-02   3.68849993e-01   2.51679987e-01  -2.45169997e-01\n",
      "    2.53809988e-01   1.36700004e-01  -3.11780006e-01  -6.32099986e-01\n",
      "   -2.50279993e-01  -3.80970001e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Word index dictionary of tokenized words\n",
    "import random\n",
    "random.seed(4829975900407156849)\n",
    "word_index=tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)\n",
    "#print(embedding_matrix[0:2])\n",
    "print(emb_mean, emb_std, (nb_words, embed_size))\n",
    "print(X_train.shape)\n",
    "print(X_train[0:70,10])\n",
    "print(embedding_matrix[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True,dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "import keras.backend as K\n",
    "def loss(y_true, y_pred):\n",
    "     return K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/3\n",
      " 49408/143613 [=========>....................] - ETA: 239s - loss: 0.6165 - acc: 0.3846"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-e62537ba84bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vaibhavs/ENVS/vqa/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def schedule(ind):\n",
    "    a = [0.002,0.003, 0.000]\n",
    "    return a[ind]\n",
    "lr = callbacks.LearningRateScheduler(schedule)\n",
    "model.fit(X_train, y, batch_size=64, epochs=3, validation_split=0.1, callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = model.predict([X_test], batch_size=1024, verbose=1)\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission[class_cloumns] = y_test\n",
    "sample_submission.to_csv('LSTM-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
